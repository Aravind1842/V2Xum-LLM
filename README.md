# V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning (AAAI 2025)
[**ğŸŒ Homepage**](https://hanghuacs.github.io/v2xum/) | [**ğŸ”¬ Paper**](https://arxiv.org/pdf/2404.12353.pdf) | [**ğŸ‘©â€ğŸ’» Code**](https://github.com/hanghuacs/V2Xum-LLM) | [**ğŸ“Š Dataset**](https://huggingface.co/datasets/hhua2/Instruct-V2Xum) | [**ğŸ¤— Model**](https://huggingface.co/hhua2/V2Xum-LLM)

## Usage

### Preparation

```bash
conda create -n v2xumllm python=3.9 -y
```

```bash
conda activate v2xumllm
```

### Demo

```
python -m v2xumllm.inference
```

## âœï¸ Citation
```bibtex
@article{hua2024v2xum,
  title={V2xum-llm: Cross-modal video summarization with temporal prompt instruction tuning},
  author={Hua, Hang and Tang, Yunlong and Xu, Chenliang and Luo, Jiebo},
  journal={arXiv preprint arXiv:2404.12353},
  year={2024}
}
```
